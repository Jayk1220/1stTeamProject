{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b1ba3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ í´ë” ìœ„ì¹˜: C:\\ai\\lecNote\\10_1stTeamProject\\naver_news\\test\n",
      "ğŸ” ë°œê²¬ëœ CSV íŒŒì¼: 231ê°œ\n",
      "\n",
      "ğŸš€ ë³‘í•© ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ìŠ¤ë§ˆíŠ¸ ê°ì§€ ëª¨ë“œ)\n",
      "\n",
      "ğŸ“Š [1ì°¨ í†µí•©] ì´ 81368ê±´ í•©ì¹¨ ì™„ë£Œ.\n",
      "   ğŸ’¡ 11ê°œ ì–¸ë¡ ì‚¬ í˜¼í•© ê°ì§€ -> 'OID' ì»¬ëŸ¼ ìœ ì§€\n",
      "\n",
      "âœ… ìµœì¢… ì €ì¥ ì™„ë£Œ: C:\\ai\\lecNote\\10_1stTeamProject\\naver_news\\test\\oids_20251201-20251221.pkl\n",
      "[ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°]\n",
      "                   ë‚ ì§œ                                        ì œëª©  \\\n",
      "0 2025-12-01 00:01:00  \"ì‚´ê²Œ ë˜ë©´ ì†Œì£¼ë‚˜ í•œ ì”\"â€¦ì¹¨ëª° ì–´ì„  ì† ì„ ì¥ì˜ í•˜ì§ ì¸ì‚¬[ê·¸í•´ ì˜¤ëŠ˜]   \n",
      "1 2025-12-01 00:06:00        [ì‚¬ì„¤] ëŒ€ë¯¸ íˆ¬ìë¡œ ê¸°ì—…ë“¤ í•´ì™¸ ì´íƒˆí•˜ëŠ”ë° ë²•ì¸ì„¸ê¹Œì§€ ì˜¬ë¦¬ë‚˜   \n",
      "2 2025-12-01 00:06:00      [ì‚¬ì„¤] ê¼¬ì¼ëŒ€ë¡œ ê¼¬ì¸ â€˜ì§€í•˜ì²  ë¬´ì„ìŠ¹ì°¨â€™, í•´ê²°ì±… ë§ˆë ¨ ì„œë‘˜ëŸ¬ì•¼   \n",
      "3 2025-12-01 00:06:00    [ì‚¬ì„¤] ì´ë²ˆì—” ì¿ íŒ¡ ê³ ê° ì •ë³´ ë‹¤ í„¸ë ¤â€¦â€˜AIì‹œëŒ€ ë³´ì•ˆâ€™ì´ ë¶ˆì•ˆí•˜ë‹¤   \n",
      "4 2025-12-01 00:31:00   \"í”¼ ê°™ì€ ê°ê·¤ 3í†¤ì´ ëª½ë•… ì‚¬ë¼ì¡Œë‹¤\"â€¦ìˆ˜í™•ì²  ì•ë‘” ì œì£¼ì„œ ë¬´ìŠ¨ ì¼ì´?   \n",
      "\n",
      "                                                  ë³¸ë¬¸  \\\n",
      "0  [ì´ë°ì¼ë¦¬ ì´ë¡œì› ê¸°ì] 2014ë…„ 12ì›” 1ì¼, ì‚¬ì¡°ì‚°ì—… ëª…íƒœì¡ì´ ì–´ì„  â€˜501ì˜¤...   \n",
      "1  [ì„œìš¸ê²½ì œ]  ì—¬ì•¼ê°€ ëŒ€ê¸°ì—… ë²•ì¸ì„¸ìœ¨ì„ ì˜¬ë¦¬ê¸°ë¡œ ê°€ë‹¥ì„ ì¡ì€ ëª¨ì–‘ìƒˆë‹¤. ì£¼ìš”êµ­ë“¤ì´ ...   \n",
      "2  [ì„œìš¸ê²½ì œ]  ì „êµ­ ì§€í•˜ì² ì˜ ì¬ì • ì†ì‹¤ì´ ëˆˆë©ì´ì²˜ëŸ¼ ë¶ˆì–´ë‚˜ê³  ìˆëŠ” ê°€ìš´ë° ì´ì— ëŒ€í•œ...   \n",
      "3  [ì„œìš¸ê²½ì œ]  êµ­ë‚´ eì»¤ë¨¸ìŠ¤ 1ìœ„ ê¸°ì—…ì¸ ì¿ íŒ¡ì—ì„œ 3370ë§Œ ê±´ì— ë‹¬í•˜ëŠ” ëŒ€ê·œëª¨ ê°œ...   \n",
      "4  [ì„œìš¸ê²½ì œ]  ê°ê·¤ ìˆ˜í™• ì² ì„ ë§ì€ ì œì£¼ì—ì„œ ë†ì‚°ë¬¼ ì ˆë„ ë²”ì£„ê°€ ê¸‰ì¦í•˜ê³  ìˆì–´ ì£¼ì˜...   \n",
      "\n",
      "                                                  ë§í¬  OID  \n",
      "0  https://n.news.naver.com/mnews/article/018/000...  018  \n",
      "1  https://n.news.naver.com/mnews/article/011/000...  011  \n",
      "2  https://n.news.naver.com/mnews/article/011/000...  011  \n",
      "3  https://n.news.naver.com/mnews/article/011/000...  011  \n",
      "4  https://n.news.naver.com/mnews/article/011/000...  011  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# ====================================================\n",
    "# [ì„¤ì •] í†µí•©í•  CSV íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë”\n",
    "# ====================================================\n",
    "# ì˜ˆ: .../naver_news/018_ì´ë°ì¼ë¦¬  ë˜ëŠ”  .../naver_news/combined\n",
    "target_folder = r\"C:\\ai\\lecNote\\10_1stTeamProject\\naver_news\\test\"\n",
    "\n",
    "# ====================================================\n",
    "# 1. íŒŒì¼ ëª©ë¡ í™•ì¸\n",
    "# ====================================================\n",
    "file_pattern = os.path.join(target_folder, \"*.csv\")\n",
    "all_files = glob.glob(file_pattern)\n",
    "\n",
    "# ê²°ê³¼ íŒŒì¼(merged_, .pkl) ì œì™¸\n",
    "all_files = [f for f in all_files if \"merged_\" not in f and \".pkl\" not in f]\n",
    "\n",
    "print(f\"ğŸ“‚ í´ë” ìœ„ì¹˜: {target_folder}\")\n",
    "print(f\"ğŸ” ë°œê²¬ëœ CSV íŒŒì¼: {len(all_files)}ê°œ\")\n",
    "\n",
    "if len(all_files) == 0:\n",
    "    print(\"âŒ íŒŒì¼ì„ í•˜ë‚˜ë„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤! ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    # ====================================================\n",
    "    # 2. íŒŒì¼ ìˆœíšŒ ë° ë³‘í•©\n",
    "    # ====================================================\n",
    "    df_list = []\n",
    "    collected_dates = []\n",
    "\n",
    "    print(\"\\nğŸš€ ë³‘í•© ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ìŠ¤ë§ˆíŠ¸ ê°ì§€ ëª¨ë“œ)\")\n",
    "\n",
    "    for i, filename in enumerate(all_files):\n",
    "        base_name = os.path.basename(filename)\n",
    "        name_no_ext = os.path.splitext(base_name)[0]\n",
    "        \n",
    "        current_oid = \"unknown\"\n",
    "        current_date = None\n",
    "\n",
    "        # --- OID/ë‚ ì§œ íŒŒì‹± ë¡œì§ (êµ¬ë²„ì „/ì‹ ë²„ì „ í˜¸í™˜) ---\n",
    "        try:\n",
    "            # Case A: oid=018&date=20251220\n",
    "            if \"oid=\" in name_no_ext and \"date=\" in name_no_ext:\n",
    "                parts = name_no_ext.split('&')\n",
    "                for part in parts:\n",
    "                    if \"oid=\" in part:\n",
    "                        current_oid = part.replace(\"oid=\", \"\")\n",
    "                    elif \"date=\" in part:\n",
    "                        current_date = part.replace(\"date=\", \"\")\n",
    "            # Case B: 018-20251220\n",
    "            elif \"-\" in name_no_ext:\n",
    "                parts = name_no_ext.split('-')\n",
    "                if len(parts) >= 2:\n",
    "                    current_oid = parts[0]\n",
    "                    current_date = parts[1]\n",
    "            \n",
    "            if current_date:\n",
    "                collected_dates.append(current_date)\n",
    "        except:\n",
    "            pass\n",
    "        # ---------------------------------------------\n",
    "\n",
    "        try:\n",
    "            # íŒŒì¼ ì½ê¸°\n",
    "            try:\n",
    "                temp_df = pd.read_csv(filename, encoding='utf-8-sig')\n",
    "            except UnicodeDecodeError:\n",
    "                temp_df = pd.read_csv(filename, encoding='cp949')\n",
    "            \n",
    "            if temp_df.empty: continue\n",
    "\n",
    "            # â˜… ì¼ë‹¨ OID ì»¬ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤ (ë‚˜ì¤‘ì— íŒë‹¨í•´ì„œ ì§€ìš¸ì§€ ê²°ì •)\n",
    "            temp_df['OID'] = current_oid\n",
    "            df_list.append(temp_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ì½ê¸° ì—ëŸ¬: {base_name} -> {e}\")\n",
    "\n",
    "    # ====================================================\n",
    "    # 3. í†µí•© ë° ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬ (ì—¬ê¸°ê°€ í•µì‹¬!)\n",
    "    # ====================================================\n",
    "    if df_list:\n",
    "        combined_df = pd.concat(df_list, ignore_index=True)\n",
    "        print(f\"\\nğŸ“Š [1ì°¨ í†µí•©] ì´ {len(combined_df)}ê±´ í•©ì¹¨ ì™„ë£Œ.\")\n",
    "\n",
    "        # ë‚ ì§œ ë³€í™˜\n",
    "        if 'ë‚ ì§œ' in combined_df.columns:\n",
    "            combined_df['ë‚ ì§œ'] = pd.to_datetime(combined_df['ë‚ ì§œ'], errors='coerce')\n",
    "        \n",
    "        # ----------------------------------------------------------\n",
    "        # â˜… [ìŠ¤ë§ˆíŠ¸ ë¡œì§] OID ê°œìˆ˜ì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°\n",
    "        # ----------------------------------------------------------\n",
    "        unique_oids = combined_df['OID'].unique()\n",
    "        unique_count = len(unique_oids)\n",
    "        \n",
    "        # ë‚ ì§œ ë²”ìœ„ ë¬¸ìì—´ ìƒì„±\n",
    "        if collected_dates:\n",
    "            collected_dates.sort()\n",
    "            date_range = f\"{collected_dates[0]}-{collected_dates[-1]}\"\n",
    "        else:\n",
    "            date_range = \"nodate\"\n",
    "\n",
    "        final_filename = \"\"\n",
    "        \n",
    "        if unique_count == 1:\n",
    "            # [ìƒí™© 1] ë‹¨ì¼ ì–¸ë¡ ì‚¬ (Single OID)\n",
    "            target_oid = unique_oids[0]\n",
    "            print(f\"   ğŸ’¡ ë‹¨ì¼ ì–¸ë¡ ì‚¬ ê°ì§€ë¨ ({target_oid}) -> 'OID' ì»¬ëŸ¼ ì‚­ì œ ë° íŒŒì¼ëª… ìµœì í™”\")\n",
    "            \n",
    "            # 1) OID ì»¬ëŸ¼ ì‚­ì œ (ë¶ˆí•„ìš”í•¨)\n",
    "            combined_df.drop(columns=['OID'], inplace=True)\n",
    "            \n",
    "            # 2) íŒŒì¼ëª…: 009_20251201-20251222.pkl\n",
    "            final_filename = f\"{target_oid}_{date_range}.pkl\"\n",
    "            \n",
    "        else:\n",
    "            # [ìƒí™© 2] ë‹¤ì¤‘ ì–¸ë¡ ì‚¬ (Multi OID)\n",
    "            print(f\"   ğŸ’¡ {unique_count}ê°œ ì–¸ë¡ ì‚¬ í˜¼í•© ê°ì§€ -> 'OID' ì»¬ëŸ¼ ìœ ì§€\")\n",
    "            \n",
    "            # 1) OID ì»¬ëŸ¼ ìœ ì§€ (í•„ìˆ˜í•¨)\n",
    "            # ë‚ ì§œì™€ OID ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "            if 'ë‚ ì§œ' in combined_df.columns:\n",
    "                combined_df = combined_df.sort_values(by=['ë‚ ì§œ', 'OID']).reset_index(drop=True)\n",
    "\n",
    "            # 2) íŒŒì¼ëª…: oids_20251201-20251222.pkl\n",
    "            final_filename = f\"oids_{date_range}.pkl\"\n",
    "\n",
    "        # ====================================================\n",
    "        # 4. ì €ì¥\n",
    "        # ====================================================\n",
    "        save_path = os.path.join(target_folder, final_filename)\n",
    "        combined_df.to_pickle(save_path)\n",
    "        \n",
    "        print(f\"\\nâœ… ìµœì¢… ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
    "        print(\"[ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°]\")\n",
    "        print(combined_df.head())\n",
    "\n",
    "    else:\n",
    "        print(\"\\nâŒ í•©ì¹  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
